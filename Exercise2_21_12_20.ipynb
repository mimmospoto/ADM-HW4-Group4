{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of unique products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74258"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ProductId.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of total reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568454"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throught a deep analysis on the products we noted that there are some duplicates ,for example the same User published the same rewiew at the same time for products which belong to the same family but having different flavour(chocolate,nut,vanilla...) or different size packaging(package of 8,16,32 pieces).We decide to mantain only one unique review for this family product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data=df.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393933, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150528</th>\n",
       "      <td>150529</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A25ACLV5KPB4W</td>\n",
       "      <td>Matt Hetling \"Matt\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1108425600</td>\n",
       "      <td>Nice cadence, catchy rhymes</td>\n",
       "      <td>In June&lt;br /&gt;I saw a charming group&lt;br /&gt;of ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150506</th>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150505</th>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150504</th>\n",
       "      <td>150505</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2PTSM496CF40Z</td>\n",
       "      <td>Jason A. Teeple \"Nobody made a greater mistak...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1210809600</td>\n",
       "      <td>A classic</td>\n",
       "      <td>Get the movie or sound track and sing along wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150503</th>\n",
       "      <td>150504</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AQEYF1AXARWJZ</td>\n",
       "      <td>Les Sinclair \"book maven\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1212278400</td>\n",
       "      <td>Chicken Soup with Rice</td>\n",
       "      <td>A very entertaining rhyming story--cleaver and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId  \\\n",
       "150528  150529  0006641040   A25ACLV5KPB4W   \n",
       "150506  150507  0006641040  A1S4A3IQ2MU7V4   \n",
       "150505  150506  0006641040  A2IW4PEEKO2R0U   \n",
       "150504  150505  0006641040  A2PTSM496CF40Z   \n",
       "150503  150504  0006641040   AQEYF1AXARWJZ   \n",
       "\n",
       "                                             ProfileName  \\\n",
       "150528                               Matt Hetling \"Matt\"   \n",
       "150506                             sally sue \"sally sue\"   \n",
       "150505                                             Tracy   \n",
       "150504  Jason A. Teeple \"Nobody made a greater mistak...   \n",
       "150503                         Les Sinclair \"book maven\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "150528                     0                       1      4  1108425600   \n",
       "150506                     1                       1      4  1191456000   \n",
       "150505                     1                       1      4  1194739200   \n",
       "150504                     1                       1      4  1210809600   \n",
       "150503                     1                       1      4  1212278400   \n",
       "\n",
       "                                           Summary  \\\n",
       "150528                 Nice cadence, catchy rhymes   \n",
       "150506               chicken soup with rice months   \n",
       "150505  Love the book, miss the hard cover version   \n",
       "150504                                   A classic   \n",
       "150503                      Chicken Soup with Rice   \n",
       "\n",
       "                                                     Text  \n",
       "150528  In June<br />I saw a charming group<br />of ro...  \n",
       "150506  This is a fun way for children to learn their ...  \n",
       "150505  I grew up reading these Sendak books, and watc...  \n",
       "150504  Get the movie or sound track and sing along wi...  \n",
       "150503  A very entertaining rhyming story--cleaver and...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we decide to merge all the reviews written by different Users but refered to the same product.This passage is necessary for the future clustering operations,otherwise the same product can belong to differet clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_series=final.groupby('ProductId').Text.apply(lambda x :','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.DataFrame(final_series).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006641040</td>\n",
       "      <td>In June&lt;br /&gt;I saw a charming group&lt;br /&gt;of ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141278509X</td>\n",
       "      <td>This product by Archer Farms is the best drink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2734888454</td>\n",
       "      <td>My dogs loves this chicken but its a product f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2841233731</td>\n",
       "      <td>This book is easy to read and the ingredients ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7310172001</td>\n",
       "      <td>My dogs love these treats. The only problems I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67552</th>\n",
       "      <td>B009RSR8HO</td>\n",
       "      <td>I've been using Fat to Skinny Zero since it wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67553</th>\n",
       "      <td>B009SF0TN6</td>\n",
       "      <td>You have to try this sauce to believe it! It s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67554</th>\n",
       "      <td>B009SR4OQ2</td>\n",
       "      <td>I bought this Hazelnut Paste (Nocciola Spread)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67555</th>\n",
       "      <td>B009WSNWC4</td>\n",
       "      <td>Purchased this product at a local store in NY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67556</th>\n",
       "      <td>B009WVB40S</td>\n",
       "      <td>I purchased this to send to my son who's away ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67557 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ProductId                                               Text\n",
       "0      0006641040  In June<br />I saw a charming group<br />of ro...\n",
       "1      141278509X  This product by Archer Farms is the best drink...\n",
       "2      2734888454  My dogs loves this chicken but its a product f...\n",
       "3      2841233731  This book is easy to read and the ingredients ...\n",
       "4      7310172001  My dogs love these treats. The only problems I...\n",
       "...           ...                                                ...\n",
       "67552  B009RSR8HO  I've been using Fat to Skinny Zero since it wa...\n",
       "67553  B009SF0TN6  You have to try this sauce to believe it! It s...\n",
       "67554  B009SR4OQ2  I bought this Hazelnut Paste (Nocciola Spread)...\n",
       "67555  B009WSNWC4  Purchased this product at a local store in NY ...\n",
       "67556  B009WVB40S  I purchased this to send to my son who's away ...\n",
       "\n",
       "[67557 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "\n",
    "At this point we have an organized dataset and we can preprocess all the reviews,for example removing stopwords,normalizing and keep only the stem of each word.\n",
    "\n",
    "Then we decide to remove all the words with length of 2 or less ,because with a quickly visual analysis we discover that there are some writing mistakes made by the Users or some special review such : **'G-R-E-A-T-P-R-O-D-U-C-T'** and we don't want to consider this special cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67557/67557 [03:45<00:00, 299.64it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-z]+') \n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer= SnowballStemmer(\"english\") # PorterStemmer \n",
    "new_text = []\n",
    "for text in tqdm(final_df['Text']):\n",
    "    letters = []\n",
    "    words=tokenizer.tokenize(text.lower())\n",
    "    tokens_without_sw = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "    for t in tokens_without_sw:\n",
    "        if len(t)>2:\n",
    "            letters.append(t)\n",
    "    new_text.append(letters)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Reviews_Text'] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop(columns=['Text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Reviews_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006641040</td>\n",
       "      <td>[june, saw, charm, group, rose, begin, droop, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141278509X</td>\n",
       "      <td>[product, archer, farm, best, drink, mix, ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2734888454</td>\n",
       "      <td>[dog, love, chicken, product, china, wont, buy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2841233731</td>\n",
       "      <td>[book, easi, read, ingredi, avail, store, unli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7310172001</td>\n",
       "      <td>[dog, love, treat, problem, encount, left, pow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId                                       Reviews_Text\n",
       "0  0006641040  [june, saw, charm, group, rose, begin, droop, ...\n",
       "1  141278509X  [product, archer, farm, best, drink, mix, ever...\n",
       "2  2734888454  [dog, love, chicken, product, china, wont, buy...\n",
       "3  2841233731  [book, easi, read, ingredi, avail, store, unli...\n",
       "4  7310172001  [dog, love, treat, problem, encount, left, pow..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Final_df.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Reviews_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006641040</td>\n",
       "      <td>['june', 'saw', 'charm', 'group', 'rose', 'beg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141278509X</td>\n",
       "      <td>['product', 'archer', 'farm', 'best', 'drink',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2734888454</td>\n",
       "      <td>['dog', 'love', 'chicken', 'product', 'china',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2841233731</td>\n",
       "      <td>['book', 'easi', 'read', 'ingredi', 'avail', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7310172001</td>\n",
       "      <td>['dog', 'love', 'treat', 'problem', 'encount',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId                                       Reviews_Text\n",
       "0  0006641040  ['june', 'saw', 'charm', 'group', 'rose', 'beg...\n",
       "1  141278509X  ['product', 'archer', 'farm', 'best', 'drink',...\n",
       "2  2734888454  ['dog', 'love', 'chicken', 'product', 'china',...\n",
       "3  2841233731  ['book', 'easi', 'read', 'ingredi', 'avail', '...\n",
       "4  7310172001  ['dog', 'love', 'treat', 'problem', 'encount',..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67557/67557 [01:05<00:00, 1024.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#for reading the column Reviews_Text as list\n",
    "df['Reviews_Text']=df.Reviews_Text.progress_apply(lambda s: list(ast.literal_eval(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our TF_IDF\n",
    "First we count the number of documents in which every word appears ,this is useful for the computation of tfidf score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67557/67557 [00:03<00:00, 17147.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# word_id:number of documents in which it is\n",
    "word_numberdoc = {}\n",
    "\n",
    "for text in tqdm(df['Reviews_Text']):\n",
    "    p = list(set(text))\n",
    "    for word in p:\n",
    "        if word in word_numberdoc:\n",
    "            word_numberdoc[word]+=1\n",
    "        else:\n",
    "            word_numberdoc[word]=1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78973"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_numberdoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_numberdoc.pkl', 'wb') as handle:\n",
    "    pickle.dump(word_numberdoc, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to mantain all that words that are at least in 10 reviews and at most in 100000 reviews. This choice is made because the words which are in few reviews aren't meaningful or they have a writing mistake. Instead words that appeas in too many reviews caracterize almost all the product so they aren't so important for the clustering. The result is saved in separated dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78973/78973 [00:00<00:00, 1827150.30it/s]\n"
     ]
    }
   ],
   "source": [
    "word_numberdoc_useful = {}\n",
    "\n",
    "for key, value in tqdm(word_numberdoc.items()):\n",
    "    if value >= 10 and value <= 100000:\n",
    "        word_numberdoc_useful[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14573"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_numberdoc_useful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the words with low document frequency and with high frequency,we reduce the original number of words from approximately 78900 to 14573.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_numberdoc_useful.pkl', 'wb') as handle:\n",
    "    pickle.dump(word_numberdoc_useful, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_numberdoc_useful.pkl', 'rb') as handle:\n",
    "    word_numberdoc_useful = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We map all the word with an integer and save them in a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_vocabulary={}\n",
    "for i,word in enumerate(word_numberdoc_useful):\n",
    "    useful_vocabulary[word]=i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('useful_vocabulary.pkl', 'wb') as handle:\n",
    "    pickle.dump(useful_vocabulary, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('useful_vocabulary.pkl', 'rb') as handle:\n",
    "    useful_vocabulary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only for this words we calculate the tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67557/67557 [00:52<00:00, 1280.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# create an inverted index with tfidf scoring\n",
    "# - keys: index number of a word\n",
    "# - values: {book in which the word appears, score of the word with respect to the book}\n",
    "N_doc = len(df)\n",
    "tfidf = defaultdict(list)\n",
    "\n",
    "count = 0\n",
    "for text in tqdm(df['Reviews_Text']):\n",
    "    n=len(text)\n",
    "    n_ij=dict(Counter(text))\n",
    "    for word in n_ij:\n",
    "        if word in word_numberdoc_useful.keys():\n",
    "            tf=n_ij[word]/n\n",
    "            Idf=np.log(N_doc/word_numberdoc_useful[word])\n",
    "            tfidf[useful_vocabulary[word]].append((count,round(tf*Idf,5)))\n",
    "        \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_useful_word.pkl', 'wb') as handle:\n",
    "    pickle.dump(tfidf, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_useful_word.pkl', 'rb') as handle:\n",
    "    tfidf_useful_word = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the tfidf we create a sparse matrix with size [number of reviews,number of features],the non-zero values are the tf_idf scores for that review and the corrispondent words which contains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14573/14573 [00:02<00:00, 6763.90it/s]\n"
     ]
    }
   ],
   "source": [
    "rows, cols, vals = [], [], []\n",
    "for key, values in tqdm(tfidf_useful_word.items()):\n",
    "    for value in values:\n",
    "        rows.append(value[0])\n",
    "        cols.append(key)\n",
    "        vals.append(value[1])\n",
    "\n",
    "X = sp.csr_matrix((vals, (rows, cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the SVD model for dimensionality reduction of sklearn,and we calculate the variance explained by different number of features to be able to find the number which explains more than the 60% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1/11 [00:01<00:10,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 4 and explained variance = 0.023372309133083396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 2/11 [00:02<00:09,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 10 and explained variance = 0.04502301745143647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 3/11 [00:03<00:09,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 15 and explained variance = 0.057641359566548846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 4/11 [00:05<00:09,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 20 and explained variance = 0.06849020358363807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 5/11 [00:08<00:11,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 50 and explained variance = 0.11704679013847143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 6/11 [00:14<00:16,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 100 and explained variance = 0.17231321487035609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 7/11 [00:24<00:20,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 150 and explained variance = 0.2142230501314303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 8/11 [00:36<00:21,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 200 and explained variance = 0.24941187111889895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 9/11 [01:15<00:33, 16.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 500 and explained variance = 0.39823140598363005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 10/11 [02:05<00:26, 26.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 700 and explained variance = 0.46844681777854585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [03:05<00:00, 16.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 800 and explained variance = 0.49851030429353405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_comp = [4,10,15,20,50,100,150,200,500,700,800] \n",
    "explained_ = [] \n",
    "for x in tqdm(n_comp):\n",
    "    svd = TruncatedSVD(n_components=x)\n",
    "    svd.fit(X)\n",
    "    explained_.append(svd.explained_variance_ratio_.sum())\n",
    "    print(\"Number of components = %r and explained variance = %r\"%(x,svd.explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:41<01:41, 101.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 1200 and explained variance = 0.5959196782893105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:52<00:00, 116.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 1500 and explained variance = 0.6517713132551776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_comp = [1200, 1500]\n",
    "for x in tqdm(n_comp):\n",
    "    svd = TruncatedSVD(n_components=x)\n",
    "    svd.fit(X)\n",
    "    explained_.append(svd.explained_variance_ratio_.sum())\n",
    "    print(\"Number of components = %r and explained variance = %r\"%(x,svd.explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_comp, explained_)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.title(\"SVD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the results obtaind from the SVD Truncated method for the reduction of the number of features, is slightly different if we apply it on the sparse matrix of **tf_idf** coefficients generated from scratch by us , and if we apply it on the sparse matrix returnd by the built in model of sklearn TfidfVectorizer which created automatically a TF-IDF matrix given a collection of documents. The reason of this is that TfidfVectorizer use a reweighting of inverse frequency and a sort of Laplace Smoothing to avoid division by zero. Taking into account the second result instead of represent each review with 14000 features we can represent them with only 800 features obtained vy SVD reduction dimensionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best 1500 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD dimension are linear combination of the original features.So for finding the 1500 features that explain 65% od the data we:\n",
    "1. Obtain all the features(words) from the vectorizer.\n",
    "\n",
    "2. Use the svd_components which is a matrix of coefficient of each features are multiplied by.\n",
    "\n",
    "3. To obtain the top 800 we sort the first dimension of svd_components and we find the relative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an inverted vocabulary index \n",
    "# - keys: index number of a word\n",
    "# - values: word\n",
    "inverted_useful_vocabulary=defaultdict(list)\n",
    "for i,word in enumerate(word_numberdoc_useful):\n",
    "    inverted_useful_vocabulary[i]=word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = [inverted_useful_vocabulary[i] for i in svd.components_[0].argsort()[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tea', 'coffe', 'flavor', 'tast', 'chocol', 'dog', 'love', 'great', 'like', 'good', 'product', 'use', 'order', 'bag', 'one', 'drink', 'candi', 'tri', 'food', 'price', 'buy', 'make', 'sauc', 'best', 'get', 'would', 'find', 'cup', 'realli', 'amazon', 'box', 'time', 'cat', 'sweet', 'eat', 'store', 'green', 'sugar', 'treat', 'mix', 'purchas', 'much', 'delici', 'cooki', 'hot', 'packag', 'littl', 'brand', 'ship', 'well', 'recommend', 'bar', 'gift', 'nice', 'better', 'favorit', 'bought', 'fresh', 'look', 'enjoy', 'also', 'bean', 'year', 'perfect', 'even', 'bottl', 'high', 'pack', 'qualiti', 'day', 'ever', 'found', 'wonder', 'want', 'salt', 'free', 'arriv', 'snack', 'made', 'ice', 'water', 'organ', 'add', 'excel', 'item', 'give', 'local', 'got', 'first', 'receiv', 'way', 'work', 'need', 'hard', 'oil', 'say', 'differ', 'milk', 'could', 'soup', 'smell', 'rice', 'cook', 'chees', 'think', 'spice', 'lot', 'chicken', 'strong', 'tasti', 'stuff', 'black', 'bit', 'thank', 'know', 'pasta', 'quick', 'blend', 'alway', 'roast', 'easi', 'size', 'mani', 'gum', 'happi', 'two', 'still', 'chip', 'never', 'sinc', 'fruit', 'come', 'cake', 'right', 'brew', 'dri', 'definit', 'thing', 'keep', 'honey', 'peanut', 'disappoint', 'mint', 'last', 'everi', 'small', 'ingredi', 'friend', 'bitter', 'without', 'can', 'expect', 'whole', 'long', 'worth', 'butter', 'back', 'seem', 'vanilla', 'put', 'smooth', 'compani', 'cracker', 'natur', 'contain', 'groceri', 'dark', 'jar', 'came', 'old', 'season', 'sure', 'regular', 'thought', 'white', 'kid', 'syrup', 'healthi', 'enough', 'lemon', 'take', 'decaf', 'bad', 'less', 'someth', 'famili', 'expens', 'howev', 'quit', 'nut', 'though', 'pleas', 'far', 'big', 'spici', 'open', 'absolut', 'light', 'bread', 'fast', 'chew', 'avail', 'cost', 'review', 'oliv', 'real', 'gluten', 'serv', 'pretti', 'calori', 'textur', 'cereal', 'juic', 'actual', 'see', 'help', 'piec', 'varieti', 'cream', 'recip', 'amaz', 'salad', 'star', 'wish', 'bake', 'home', 'ginger', 'amount', 'rich', 'seed', 'color', 'cinnamon', 'money', 'pepper', 'low', 'feel', 'husband', 'morn', 'new', 'month', 'usual', 'kind', 'christma', 'full', 'almost', 'powder', 'anoth', 'chai', 'problem', 'almond', 'anyth', 'half', 'sever', 'reason', 'carri', 'orang', 'red', 'top', 'abl', 'larg', 'case', 'per', 'around', 'leav', 'aroma', 'live', 'popcorn', 'hope', 'com', 'coconut', 'seller', 'said', 'prefer', 'deal', 'noth', 'fine', 'breakfast', 'glad', 'appl', 'especi', 'dish', 'servic', 'sweeten', 'save', 'start', 'onlin', 'peopl', 'meat', 'packet', 'caffein', 'away', 'diet', 'meal', 'ounc', 'sell', 'yummi', 'instead', 'week', 'noodl', 'cherri', 'market', 'stick', 'fill', 'surpris', 'pound', 'probabl', 'exact', 'fat', 'pay', 'may', 'corn', 'place', 'must', 'sent', 'everyth', 'minut', 'cold', 'satisfi', 'gave', 'compar', 'pod', 'type', 'mild', 'pictur', 'stock', 'three', 'everyon', 'mustard', 'sour', 'anyon', 'hous', 'awesom', 'soft', 'melt', 'hand', 'ago', 'list', 'date', 'cheaper', 'heat', 'garlic', 'yet', 'fan', 'care', 'son', 'dress', 'extra', 'valu', 'deliveri', 'chili', 'peach', 'salti', 'call', 'origin', 'mayb', 'health', 'jelli', 'mouth', 'fish', 'licoric', 'tin', 'went', 'might', 'daughter', 'longer', 'stop', 'strawberri', 'next', 'other', 'wife', 'parti', 'loos', 'super', 'beef', 'end', 'els', 'tomato', 'pot', 'potato', 'wheat', 'french', 'offer', 'flour', 'refresh', 'deliv', 'special', 'bone', 'ground', 'plus', 'addict', 'version', 'past', 'shop', 'fantast', 'second', 'person', 'least', 'let', 'fact', 'wrap', 'return', 'pop', 'although', 'individu', 'slight', 'includ', 'restaur', 'run', 'bite', 'goe', 'either', 'raspberri', 'dip', 'turn', 'bulk', 'addit', 'decid', 'read', 'conveni', 'plastic', 'crunchi', 'total', 'chang', 'soda', 'caramel', 'wait', 'descript', 'tell', 'coupl', 'line', 'www', 'protein', 'delight', 'leaf', 'took', 'starbuck', 'http', 'babi', 'wine', 'espresso', 'wrong', 'cannot', 'part', 'href', 'plain', 'egg', 'drinker', 'basket', 'normal', 'direct', 'grey', 'gummi', 'hint', 'side', 'experi', 'rememb', 'earl', 'label', 'brown', 'ask', 'jasmin', 'wast', 'creami', 'pick', 'energi', 'condit', 'vinegar', 'combin', 'stale', 'peppermint', 'lover', 'weight', 'grain', 'instant', 'believ', 'pleasant', 'custom', 'continu', 'particular', 'broken', 'consist', 'feed', 'rather', 'choic', 'beauti', 'recent', 'artifici', 'etc', 'bodi', 'close', 'search', 'cut', 'cocoa', 'sold', 'smaller', 'state', 'hit', 'share', 'machin', 'soy', 'simpli', 'plant', 'fair', 'guess', 'clean', 'veget', 'base', 'shape', 'night', 'mango', 'prompt', 'describ', 'notic', 'huge', 'chewi', 'world', 'mother', 'prepar', 'pure', 'sometim', 'near', 'area', 'coat', 'extrem', 'jerki', 'lime', 'supermarket', 'steep', 'glass', 'altern', 'often', 'fri', 'name', 'sodium', 'teeth', 'vendor', 'birthday', 'pet', 'except', 'bold', 'sale', 'blue', 'someon', 'cover', 'dinner', 'unfortun', 'life', 'flower', 'anywher', 'finish', 'steak', 'eaten', 'stay', 'raw', 'soon', 'acid', 'insid', 'bring', 'balanc', 'becom', 'smoke', 'berri', 'singl', 'larger', 'seal', 'final', 'similar', 'send', 'four', 'complet', 'cours', 'rate', 'hour', 'truffl', 'expir', 'salmon', 'advertis', 'dollar', 'discov', 'english', 'excit', 'certain', 'tuna', 'summer', 'stomach', 'present', 'quantiti', 'onion', 'hazelnut', 'bowl', 'cheap', 'carb', 'issu', 'alreadi', 'suppos', 'blueberri', 'holiday', 'pricey', 'set', 'left', 'yum', 'dessert', 'pork', 'result', 'curri', 'miss', 'roll', 'check', 'italian', 'tart', 'mean', 'show', 'along', 'lunch', 'note', 'oatmeal', 'pie', 'replac', 'fun', 'ate', 'bbq', 'difficult', 'beat', 'impress', 'truli', 'toast', 'uniqu', 'aftertast', 'jam', 'weak', 'saw', 'biscuit', 'extract', 'consid', 'gone', 'true', 'togeth', 'sampl', 'picki', 'overal', 'grill', 'thick', 'drop', 'mine', 'futur', 'herbal', 'easili', 'given', 'keurig', 'warm', 'mom', 'fruiti', 'hook', 'rose', 'gourmet', 'sit', 'crunch', 'told', 'idea', 'kick', 'break', 'slice', 'paid', 'china', 'throw', 'medium', 'plan', 'sprinkl', 'charg', 'non', 'content', 'pretzel', 'salsa', 'suggest', 'tradit', 'overpow', 'clear', 'bland', 'banana', 'thin', 'process', 'preserv', 'provid', 'busi', 'pumpkin', 'veggi', 'beer', 'sandwich', 'tini', 'due', 'anymor', 'batch', 'maker', 'pancak', 'opinion', 'granola', 'puppi', 'subtl', 'shipment', 'crave', 'boil', 'substitut', 'benefit', 'decent', 'entir', 'option', 'trip', 'five', 'brought', 'effect', 'fiber', 'cute', 'today', 'herb', 'yes', 'pour', 'interest', 'twice', 'sourc', 'crazi', 'spread', 'crisp', 'formula', 'count', 'import', 'simpl', 'nutrit', 'remind', 'favor', 'touch', 'allergi', 'pouch', 'diabet', 'wow', 'pickl', 'none', 'thrill', 'daili', 'homemad', 'websit', 'point', 'produc', 'rest', 'subscrib', 'style', 'mushroom', 'easier', 'caus', 'six', 'moist', 'pizza', 'relax', 'seen', 'complaint', 'anyway', 'liquid', 'raisin', 'cool', 'microwav', 'vet', 'switch', 'horribl', 'sea', 'visit', 'site', 'happen', 'grind', 'matter', 'delic', 'done', 'select', 'oolong', 'later', 'word', 'bubbl', 'within', 'shell', 'lower', 'mind', 'incred', 'appreci', 'cranberri', 'lbs', 'ball', 'travel', 'walmart', 'chamomil', 'chemic', 'okay', 'indian', 'general', 'gravi', 'stir', 'kitchen', 'offic', 'sorri', 'follow', 'unlik', 'yogurt', 'american', 'guest', 'unless', 'kona', 'stevia', 'doubl', 'dont', 'watch', 'hate', 'digest', 'usa', 'forward', 'marinad', 'previous', 'lack', 'worri', 'train', 'rub', 'hold', 'grape', 'browni', 'bacon', 'vitamin', 'short', 'costco', 'lipton', 'fit', 'stronger', 'serious', 'pea', 'suppli', 'fabul', 'gram', 'cashew', 'sort', 'grow', 'everyday', 'over', 'turkey', 'bigger', 'winter', 'terribl', 'bear', 'afternoon', 'readi', 'sister', 'mapl', 'root', 'otherwis', 'figur', 'mail', 'shelf', 'beverag', 'mountain', 'mention', 'crystal', 'creamer', 'basic', 'possibl', 'chunk', 'immedi', 'main', 'rip', 'realiz', 'overwhelm', 'chines', 'job', 'children', 'twine', 'wed', 'mess', 'typic', 'flavour', 'late', 'pineappl', 'yellow', 'sardin', 'frost', 'inform', 'muffin', 'crispi', 'healthier', 'standard', 'kit', 'perhap', 'heaven', 'refund', 'instruct', 'consum', 'allow', 'manufactur', 'move', 'assort', 'somewhat', 'cent', 'vegan', 'stand', 'higher', 'form', 'spoon', 'rooibo', 'sesam', 'level', 'prime', 'plenti', 'oat', 'skin', 'fell', 'wild', 'threw', 'pecan', 'tree', 'alot', 'dent', 'heard', 'sooth', 'paper', 'matcha', 'chanc', 'apricot', 'freez', 'pear', 'bottom', 'poor', 'number', 'gold', 'asian', 'honest', 'agre', 'refriger', 'rock', 'imagin', 'learn', 'most', 'fall', 'latt', 'spend', 'worst', 'power', 'smoothi', 'burn', 'outstand', 'avoid', 'heavi', 'afford', 'age', 'sick', 'sprout', 'frozen', 'farm', 'chop', 'appear', 'grew', 'buck', 'outsid', 'blood', 'decor', 'law', 'broth', 'requir', 'tabl', 'door', 'cupcak', 'scent', 'sausag', 'contact', 'mocha', 'lol', 'infus', 'sip', 'equal', 'correct', 'shake', 'sticki', 'straight', 'mini', 'handl', 'crumbl', 'premium', 'round', 'whatev', 'kept', 'rawhid', 'portion', 'thai', 'taffi', 'school', 'retail', 'knew', 'mistak', 'known', 'pud', 'damag', 'boy', 'fridg', 'discontinu', 'gallon', 'concentr', 'room', 'sad', 'nutti', 'troubl', 'across', 'intens', 'shrimp', 'tend', 'write', 'japanes', 'sound', 'cheddar', 'wafer', 'remov', 'flake', 'control', 'test', 'understand', 'concern', 'upon', 'drank', 'crust', 'warn', 'felt', 'pantri', 'distinct', 'tazo', 'terrif', 'heart', 'fix', 'manner', 'eater', 'town', 'splenda', 'introduc', 'citrus', 'bud', 'mate', 'lid', 'reorder', 'alon', 'stuck', 'pink', 'robust', 'authent', 'sensit', 'joe', 'gotten', 'mellow', 'aromat', 'reciev', 'child', 'hershey', 'tangi', 'comment', 'breath', 'pan', 'superior', 'lose', 'various', 'father', 'countri', 'spot', 'safe', 'crush', 'relat', 'tire', 'enhanc', 'stapl', 'cafe', 'deep', 'fudg', 'toffe', 'bewar', 'guy', 'adult', 'pass', 'irish', 'fanci', 'overpr', 'press', 'improv', 'south', 'hesit', 'balsam', 'pistachio', 'creat', 'lemonad', 'toy', 'tooth', 'lost', 'sampler', 'england', 'filter', 'solid', 'nasti', 'stew', 'weird', 'taco', 'supplier', 'pomegran', 'walnut', 'bunch', 'memori', 'german', 'hair', 'teaspoon', 'internet', 'cant', 'dairi', 'bigelow', 'carrot', 'teabag', 'itali', 'girl', 'upset', 'mexican', 'air', 'limit', 'freezer', 'club', 'boost', 'shot', 'liter', 'mill', 'golden', 'wrapper', 'stash', 'defin', 'senseo', 'mug', 'research', 'rave', 'strang', 'childhood', 'mislead', 'ham', 'averag', 'classic', 'trade', 'reduc', 'trust', 'msg', 'current', 'brother', 'dad', 'head', 'tablespoon', 'photo', 'everywher', 'obvious', 'promis', 'numi', 'claim', 'elsewher', 'california', 'odd', 'whether', 'grinder', 'allerg', 'apart', 'germani', 'whenev', 'ridicul', 'superb', 'wet', 'spaghetti', 'bed', 'grown', 'gas', 'burger', 'yeast', 'lamb', 'waffl', 'purpos', 'clove', 'drive', 'eye', 'post', 'measur', 'handi', 'antioxid', 'tender', 'sam', 'creme', 'specif', 'lollipop', 'grade', 'soak', 'book', 'third', 'popular', 'lavend', 'alcohol', 'peel', 'pull', 'crumb', 'separ', 'awhil', 'doubt', 'cube', 'ton', 'bother', 'middl', 'system', 'fig', 'choos', 'oven', 'locat', 'bare', 'imposs', 'scratch', 'toss', 'island', 'rum', 'die', 'bargain', 'theme', 'proper', 'email', 'sleep', 'buyer', 'butteri', 'fragrant', 'firm', 'recipi', 'belli', 'strength', 'shown', 'via', 'mixtur', 'kitti', 'assum', 'sunflow', 'spoil', 'sens', 'cane', 'jalapeno', 'complex', 'kibbl', 'titl', 'sun', 'remain', 'fashion', 'major', 'clam', 'occas', 'earli', 'leak', 'respons', 'tip', 'forev', 'center', 'web', 'hibiscus', 'admit', 'talk', 'bergamot', 'grab', 'layer', 'complain', 'punch', 'bonus', 'throat', 'pre', 'foil', 'ran', 'sweeter', 'saffron', 'celesti', 'collect', 'pleasur', 'car', 'hawaii', 'marshmallow', 'becam', 'cardboard', 'awar', 'inch', 'texa', 'reseal', 'basi', 'trader', 'harder', 'rib', 'bill', 'increas', 'crack', 'rare', 'tough', 'whip', 'unabl', 'fructos', 'san', 'earth', 'anytim', 'comparison', 'updat', 'pearl', 'folk', 'ador', 'calm', 'win', 'wasabi', 'darjeel', 'wake', 'vegetarian', 'edibl', 'spray', 'squar', 'penni', 'anim', 'depend', 'occasion', 'palat', 'purs', 'smoki', 'man', 'seafood', 'compliment', 'halloween', 'parent', 'brewer', 'design', 'load', 'bright', 'ramen', 'shelv', 'tongu', 'spent', 'donut', 'chef', 'vacat', 'medicin', 'zero', 'dissolv', 'bulli', 'grate', 'lentil', 'ten', 'ear', 'empti', 'dust', 'question', 'comfort', 'canist', 'shame', 'japan', 'appar', 'beyond', 'negat', 'malt', 'grass', 'ketchup', 'disgust', 'paprika', 'cocktail', 'luck', 'taken', 'member', 'floral', 'xylitol', 'wors', 'biscotti', 'frequent', 'nutriti', 'decaffein', 'smokey', 'subscript', 'bob', 'accord', 'sugari', 'buffalo', 'gross', 'begin', 'warehous', 'pain', 'indic', 'lab', 'play', 'desir', 'discount', 'easter', 'regret', 'pocket', 'match', 'face', 'watermelon', 'tropic', 'valentin', 'duck', 'glaze', 'lighter', 'savori', 'tub', 'scoop', 'mart', 'front', 'pill', 'target', 'tight', 'tasteless', 'hungri', 'ceylon', 'min', 'junk', 'reach', 'filler', 'ranch', 'weather', 'unit', 'supplement', 'mac', 'appeal', 'request', 'besid', 'minti', 'among', 'shower', 'chipotl', 'walk', 'mushi', 'period', 'disappear', 'grocer', 'ahmad', 'kinda', 'royal', 'dough', 'wont', 'plum', 'winner', 'cider', 'fault', 'funni', 'stuf', 'agav', 'trick', 'florida', 'worker', 'finger', 'mayo', 'wide', 'wing', 'quinoa', 'initi', 'multipl', 'accept', 'young', 'older', 'flat', 'oili', 'econom', 'india', 'therefor', 'neither', 'folger', 'inexpens', 'wash', 'thicker', 'dissapoint', 'somewher', 'garden', 'experienc', 'common', 'citi', 'shortbread', 'british', 'manag', 'dozen', 'spring', 'fragranc', 'caviar', 'pitcher', 'sushi', 'reward', 'movi', 'seattl', 'spearmint', 'dispens', 'forget', 'europ', 'drip', 'class', 'wateri', 'sharp', 'fake', 'flax', 'twist', 'success', 'thru', 'temperatur', 'that', 'attent', 'burnt', 'bore', 'toler', 'cola', 'human', 'tortilla', 'thumb', 'tassimo', 'macadamia']\n"
     ]
    }
   ],
   "source": [
    "print(best_features[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_1500 = best_features[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an vocabulary index with only 1500 words\n",
    "# - keys: word\n",
    "# - values: index number of a word\n",
    "vocabulary_1500={}\n",
    "i=0\n",
    "for elem in best_features_1500:\n",
    "    vocabulary_1500[elem]=i\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67557/67557 [02:18<00:00, 488.78it/s] \n"
     ]
    }
   ],
   "source": [
    "# create an inverted index with tfidf scoring\n",
    "# - keys: index number of a word\n",
    "# - values: {book in which the word appears, score of the word with respect to the book}\n",
    "N_doc = len(df)\n",
    "tfidf_1500 = defaultdict(list)\n",
    "\n",
    "count = 0\n",
    "for text in tqdm(df['Reviews_Text']):\n",
    "    n=len(text)\n",
    "    n_ij=dict(Counter(text))\n",
    "    for word in n_ij:\n",
    "        if word in best_features_1500:\n",
    "            tf=n_ij[word]/n\n",
    "            Idf=np.log(N_doc/word_numberdoc_useful[word])\n",
    "            tfidf_1500[vocabulary_1500[word]].append((count,round(tf*Idf,5)))\n",
    "        \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.zeros((67557,1500),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:05<00:00, 261.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for key,value in tqdm(tfidf_1500.items()):\n",
    "    for va in value:\n",
    "        a[va[0],key]=va[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df = pd.DataFrame(a,columns=best_features_1500)\n",
    "matrix_df.insert(loc=0,column='ProductId',value=df['ProductId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>tea</th>\n",
       "      <th>coffe</th>\n",
       "      <th>flavor</th>\n",
       "      <th>tast</th>\n",
       "      <th>chocol</th>\n",
       "      <th>dog</th>\n",
       "      <th>love</th>\n",
       "      <th>great</th>\n",
       "      <th>like</th>\n",
       "      <th>...</th>\n",
       "      <th>attent</th>\n",
       "      <th>burnt</th>\n",
       "      <th>bore</th>\n",
       "      <th>toler</th>\n",
       "      <th>cola</th>\n",
       "      <th>human</th>\n",
       "      <th>tortilla</th>\n",
       "      <th>thumb</th>\n",
       "      <th>tassimo</th>\n",
       "      <th>macadamia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006641040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01074</td>\n",
       "      <td>0.00703</td>\n",
       "      <td>0.00354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141278509X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04172</td>\n",
       "      <td>0.01719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01949</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2734888454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13303</td>\n",
       "      <td>0.03974</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2841233731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02815</td>\n",
       "      <td>0.04611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7310172001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.00105</td>\n",
       "      <td>0.00074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12824</td>\n",
       "      <td>0.01602</td>\n",
       "      <td>0.00827</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId  tea    coffe   flavor     tast  chocol      dog     love  \\\n",
       "0  0006641040  0.0  0.00000  0.00000  0.00000     0.0  0.00000  0.01074   \n",
       "1  141278509X  0.0  0.00000  0.04172  0.01719     0.0  0.00000  0.00000   \n",
       "2  2734888454  0.0  0.00000  0.00000  0.00000     0.0  0.13303  0.03974   \n",
       "3  2841233731  0.0  0.00000  0.00000  0.00000     0.0  0.00000  0.00000   \n",
       "4  7310172001  0.0  0.00077  0.00105  0.00074     0.0  0.12824  0.01602   \n",
       "\n",
       "     great     like  ...   attent  burnt     bore  toler  cola    human  \\\n",
       "0  0.00703  0.00354  ...  0.00290    0.0  0.00000    0.0   0.0  0.00000   \n",
       "1  0.01949  0.00000  ...  0.00000    0.0  0.00000    0.0   0.0  0.00000   \n",
       "2  0.00000  0.00000  ...  0.00000    0.0  0.00000    0.0   0.0  0.00000   \n",
       "3  0.02815  0.04611  ...  0.00000    0.0  0.00000    0.0   0.0  0.00000   \n",
       "4  0.00827  0.00517  ...  0.00677    0.0  0.00077    0.0   0.0  0.00074   \n",
       "\n",
       "   tortilla  thumb  tassimo  macadamia  \n",
       "0       0.0    0.0      0.0        0.0  \n",
       "1       0.0    0.0      0.0        0.0  \n",
       "2       0.0    0.0      0.0        0.0  \n",
       "3       0.0    0.0      0.0        0.0  \n",
       "4       0.0    0.0      0.0        0.0  \n",
       "\n",
       "[5 rows x 1501 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('matrix_df.pkl', 'wb') as handle:\n",
    "    pickle.dump(matrix_df, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('matrix_df.pkl', 'rb') as handle:\n",
    "    matrix_df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
