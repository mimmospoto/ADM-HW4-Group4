{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('/Users/domenicospoto/Desktop/Sapienza/MScDataScience/AlgorithmicMethodsofDataMiningandLaboratory/HW4/Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568438 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "ProductId                  0\n",
       "UserId                     0\n",
       "ProfileName               16\n",
       "HelpfulnessNumerator       0\n",
       "HelpfulnessDenominator     0\n",
       "Score                      0\n",
       "Time                       0\n",
       "Summary                   27\n",
       "Text                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ProductId', 'Text']\n",
    "file = file[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''def clean_text(text):\n",
    "    words = word_tokenize(text)    \n",
    "    filtered_words = []\n",
    "    for word in words:        \n",
    "        if word.lower() not in stop_words and word.isalpha():\n",
    "            filtered_words.append(lemmatizer.lemmatize(word.lower()))\n",
    "    return filtered_words'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 568454/568454 [06:32<00:00, 1446.72it/s] \n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-z]+') \n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer= SnowballStemmer(\"english\") # PorterStemmer \n",
    "new_text = []\n",
    "for text in tqdm(file['Text']):\n",
    "    words=tokenizer.tokenize(text.lower())\n",
    "    tokens_without_sw = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "    new_text.append(tokens_without_sw)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file['Text_snow'] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STARE ATTENTI A RUNNARE SOLO UNA VOLTA\n",
    "# save new dataframe to pickle\n",
    "# MANTENIAMO LA COLONNA DI TEXT VECCHIA\n",
    "with open('file_snowball.pkl', 'wb') as handle:\n",
    "    pickle.dump(file, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open new dataframe to pickle\n",
    "with open('/Users/domenicospoto/Desktop/Sapienza/MScDataScience/AlgorithmicMethodsofDataMiningandLaboratory/HW4/file_snowball.pkl', 'rb') as handle:\n",
    "    new_file_snow = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snow = new_file_snow[['ProductId', 'Text_snow']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Text_snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>[bought, sever, vital, can, dog, food, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>[product, arriv, label, jumbo, salt, peanut, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>[confect, around, centuri, light, pillowi, cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>[look, secret, ingredi, robitussin, believ, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>[great, taffi, great, price, wide, assort, yum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>[great, sesam, chicken, good, better, restur, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>[disappoint, flavor, chocol, note, especi, wea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>[star, small, give, one, train, session, tri, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>[best, treat, train, reward, dog, good, groom,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>[satisfi, product, advertis, use, cereal, raw,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ProductId                                          Text_snow\n",
       "0       B001E4KFG0  [bought, sever, vital, can, dog, food, product...\n",
       "1       B00813GRG4  [product, arriv, label, jumbo, salt, peanut, p...\n",
       "2       B000LQOCH0  [confect, around, centuri, light, pillowi, cit...\n",
       "3       B000UA0QIQ  [look, secret, ingredi, robitussin, believ, fo...\n",
       "4       B006K2ZZ7K  [great, taffi, great, price, wide, assort, yum...\n",
       "...            ...                                                ...\n",
       "568449  B001EO7N10  [great, sesam, chicken, good, better, restur, ...\n",
       "568450  B003S1WTCU  [disappoint, flavor, chocol, note, especi, wea...\n",
       "568451  B004I613EE  [star, small, give, one, train, session, tri, ...\n",
       "568452  B004I613EE  [best, treat, train, reward, dog, good, groom,...\n",
       "568453  B001LR2CU2  [satisfi, product, advertis, use, cereal, raw,...\n",
       "\n",
       "[568454 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 568454/568454 [00:06<00:00, 90868.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bought': 1,\n",
       " 'sever': 2,\n",
       " 'vital': 3,\n",
       " 'can': 4,\n",
       " 'dog': 5,\n",
       " 'food': 6,\n",
       " 'product': 7,\n",
       " 'found': 8,\n",
       " 'good': 9,\n",
       " 'qualiti': 10,\n",
       " 'look': 11,\n",
       " 'like': 12,\n",
       " 'stew': 13,\n",
       " 'process': 14,\n",
       " 'meat': 15,\n",
       " 'smell': 16,\n",
       " 'better': 17,\n",
       " 'labrador': 18,\n",
       " 'finicki': 19,\n",
       " 'appreci': 20,\n",
       " 'arriv': 21,\n",
       " 'label': 22,\n",
       " 'jumbo': 23,\n",
       " 'salt': 24,\n",
       " 'peanut': 25,\n",
       " 'actual': 26,\n",
       " 'small': 27,\n",
       " 'size': 28,\n",
       " 'unsalt': 29,\n",
       " 'sure': 30,\n",
       " 'error': 31,\n",
       " 'vendor': 32,\n",
       " 'intend': 33,\n",
       " 'repres': 34,\n",
       " 'confect': 35,\n",
       " 'around': 36,\n",
       " 'centuri': 37,\n",
       " 'light': 38,\n",
       " 'pillowi': 39,\n",
       " 'citrus': 40,\n",
       " 'gelatin': 41,\n",
       " 'nut': 42,\n",
       " 'case': 43,\n",
       " 'filbert': 44,\n",
       " 'cut': 45,\n",
       " 'tini': 46,\n",
       " 'squar': 47,\n",
       " 'liber': 48,\n",
       " 'coat': 49,\n",
       " 'powder': 50,\n",
       " 'sugar': 51,\n",
       " 'mouth': 52,\n",
       " 'heaven': 53,\n",
       " 'chewi': 54,\n",
       " 'flavor': 55,\n",
       " 'high': 56,\n",
       " 'recommend': 57,\n",
       " 'yummi': 58,\n",
       " 'treat': 59,\n",
       " 'familiar': 60,\n",
       " 'stori': 61,\n",
       " 'lewi': 62,\n",
       " 'lion': 63,\n",
       " 'witch': 64,\n",
       " 'wardrob': 65,\n",
       " 'seduc': 66,\n",
       " 'edmund': 67,\n",
       " 'sell': 68,\n",
       " 'brother': 69,\n",
       " 'sister': 70,\n",
       " 'secret': 71,\n",
       " 'ingredi': 72,\n",
       " 'robitussin': 73,\n",
       " 'believ': 74,\n",
       " 'got': 75,\n",
       " 'addit': 76,\n",
       " 'root': 77,\n",
       " 'beer': 78,\n",
       " 'extract': 79,\n",
       " 'order': 80,\n",
       " 'made': 81,\n",
       " 'cherri': 82,\n",
       " 'soda': 83,\n",
       " 'medicin': 84,\n",
       " 'great': 85,\n",
       " 'taffi': 86,\n",
       " 'price': 87,\n",
       " 'wide': 88,\n",
       " 'assort': 89,\n",
       " 'deliveri': 90,\n",
       " 'quick': 91,\n",
       " 'lover': 92,\n",
       " 'deal': 93,\n",
       " 'wild': 94,\n",
       " 'hair': 95,\n",
       " 'five': 96,\n",
       " 'pound': 97,\n",
       " 'bag': 98,\n",
       " 'enjoy': 99,\n",
       " 'mani': 100,\n",
       " 'watermelon': 101,\n",
       " 'melon': 102,\n",
       " 'peppermint': 103,\n",
       " 'grape': 104,\n",
       " 'etc': 105,\n",
       " 'complaint': 106,\n",
       " 'bit': 107,\n",
       " 'much': 108,\n",
       " 'red': 109,\n",
       " 'black': 110,\n",
       " 'licoric': 111,\n",
       " 'piec': 112,\n",
       " 'particular': 113,\n",
       " 'favorit': 114,\n",
       " 'kid': 115,\n",
       " 'husband': 116,\n",
       " 'last': 117,\n",
       " 'two': 118,\n",
       " 'week': 119,\n",
       " 'would': 120,\n",
       " 'brand': 121,\n",
       " 'delight': 122,\n",
       " 'saltwat': 123,\n",
       " 'soft': 124,\n",
       " 'candi': 125,\n",
       " 'individu': 126,\n",
       " 'wrap': 127,\n",
       " 'well': 128,\n",
       " 'none': 129,\n",
       " 'stuck': 130,\n",
       " 'togeth': 131,\n",
       " 'happen': 132,\n",
       " 'expens': 133,\n",
       " 'version': 134,\n",
       " 'fraling': 135,\n",
       " 'serv': 136,\n",
       " 'beach': 137,\n",
       " 'theme': 138,\n",
       " 'parti': 139,\n",
       " 'everyon': 140,\n",
       " 'love': 141,\n",
       " 'amaz': 142,\n",
       " 'definit': 143,\n",
       " 'buy': 144,\n",
       " 'satisfi': 145,\n",
       " 'right': 146,\n",
       " 'most': 147,\n",
       " 'sprout': 148,\n",
       " 'cat': 149,\n",
       " 'eat': 150,\n",
       " 'grass': 151,\n",
       " 'rotat': 152,\n",
       " 'wheatgrass': 153,\n",
       " 'rye': 154,\n",
       " 'healthi': 155,\n",
       " 'digest': 156,\n",
       " 'also': 157,\n",
       " 'puppi': 158,\n",
       " 'requir': 159,\n",
       " 'amount': 160,\n",
       " 'everi': 161,\n",
       " 'feed': 162,\n",
       " 'know': 163,\n",
       " 'cactus': 164,\n",
       " 'tequila': 165,\n",
       " 'uniqu': 166,\n",
       " 'combin': 167,\n",
       " 'flavour': 168,\n",
       " 'hot': 169,\n",
       " 'sauc': 170,\n",
       " 'make': 171,\n",
       " 'one': 172,\n",
       " 'kind': 173,\n",
       " 'pick': 174,\n",
       " 'bottl': 175,\n",
       " 'trip': 176,\n",
       " 'brought': 177,\n",
       " 'back': 178,\n",
       " 'home': 179,\n",
       " 'total': 180,\n",
       " 'blown': 181,\n",
       " 'away': 182,\n",
       " 'realiz': 183,\n",
       " 'simpli': 184,\n",
       " 'find': 185,\n",
       " 'anywher': 186,\n",
       " 'citi': 187,\n",
       " 'bum': 188,\n",
       " 'magic': 189,\n",
       " 'internet': 190,\n",
       " 'ecstat': 191,\n",
       " 'mean': 192,\n",
       " 'realli': 193,\n",
       " 'want': 194,\n",
       " 'tasteless': 195,\n",
       " 'burn': 196,\n",
       " 'throat': 197,\n",
       " 'grab': 198,\n",
       " 'picant': 199,\n",
       " 'gourmet': 200,\n",
       " 'inclan': 201,\n",
       " 'tast': 202,\n",
       " 'never': 203,\n",
       " 'use': 204,\n",
       " 'thank': 205,\n",
       " 'person': 206,\n",
       " 'incred': 207,\n",
       " 'servic': 208,\n",
       " 'boy': 209,\n",
       " 'need': 210,\n",
       " 'lose': 211,\n",
       " 'weight': 212,\n",
       " 'put': 213,\n",
       " 'floor': 214,\n",
       " 'chubbi': 215,\n",
       " 'guy': 216,\n",
       " 'protein': 217,\n",
       " 'rich': 218,\n",
       " 'higher': 219,\n",
       " 'skinni': 220,\n",
       " 'jump': 221,\n",
       " 'sit': 222,\n",
       " 'stale': 223,\n",
       " 'ounc': 224,\n",
       " 'happili': 225,\n",
       " 'felida': 226,\n",
       " 'platinum': 227,\n",
       " 'year': 228,\n",
       " 'new': 229,\n",
       " 'shape': 230,\n",
       " 'differ': 231,\n",
       " 'tri': 232,\n",
       " 'first': 233,\n",
       " 'bowl': 234,\n",
       " 'full': 235,\n",
       " 'kitti': 236,\n",
       " 'touch': 237,\n",
       " 'notic': 238,\n",
       " 'similar': 239,\n",
       " 'review': 240,\n",
       " 'relat': 241,\n",
       " 'formula': 242,\n",
       " 'chang': 243,\n",
       " 'past': 244,\n",
       " 'unfortun': 245,\n",
       " 'came': 246,\n",
       " 'secur': 247,\n",
       " 'pack': 248,\n",
       " 'fresh': 249,\n",
       " 'delici': 250,\n",
       " 'twizzler': 251,\n",
       " 'strawberri': 252,\n",
       " 'guilti': 253,\n",
       " 'pleasur': 254,\n",
       " 'six': 255,\n",
       " 'son': 256,\n",
       " 'daughter': 257,\n",
       " 'shipment': 258,\n",
       " 'hit': 259,\n",
       " 'spot': 260,\n",
       " 'exact': 261,\n",
       " 'expect': 262,\n",
       " 'packag': 263,\n",
       " 'watch': 264,\n",
       " 'movi': 265,\n",
       " 'sweet': 266,\n",
       " 'transfer': 267,\n",
       " 'zip': 268,\n",
       " 'lock': 269,\n",
       " 'baggi': 270,\n",
       " 'stay': 271,\n",
       " 'take': 272,\n",
       " 'time': 273,\n",
       " 'purchas': 274,\n",
       " 'share': 275,\n",
       " 'other': 276,\n",
       " 'childhood': 277,\n",
       " 'lancast': 278,\n",
       " 'pennsylvania': 279,\n",
       " 'inc': 280,\n",
       " 'oldest': 281,\n",
       " 'confectioneri': 282,\n",
       " 'firm': 283,\n",
       " 'unit': 284,\n",
       " 'state': 285,\n",
       " 'subsidiari': 286,\n",
       " 'hershey': 287,\n",
       " 'compani': 288,\n",
       " 'establish': 289,\n",
       " 'young': 290,\n",
       " 'smyli': 291,\n",
       " 'appl': 292,\n",
       " 'twist': 293,\n",
       " 'green': 294,\n",
       " 'color': 295,\n",
       " 'blue': 296,\n",
       " 'raspberri': 297,\n",
       " 'keep': 298,\n",
       " 'dri': 299,\n",
       " 'cool': 300,\n",
       " 'place': 301,\n",
       " 'fridg': 302,\n",
       " 'accord': 303,\n",
       " 'guin': 304,\n",
       " 'book': 305,\n",
       " 'record': 306,\n",
       " 'longest': 307,\n",
       " 'ever': 308,\n",
       " 'measur': 309,\n",
       " 'feet': 310,\n",
       " 'break': 311,\n",
       " 'becam': 312,\n",
       " 'world': 313,\n",
       " 'juli': 314,\n",
       " 'kosher': 315,\n",
       " 'deliv': 316,\n",
       " 'fast': 317,\n",
       " 'reason': 318,\n",
       " 'bound': 319,\n",
       " 'unabl': 320,\n",
       " 'get': 321,\n",
       " 'store': 322,\n",
       " 'perfect': 323,\n",
       " 'addict': 324,\n",
       " 'amazon': 325,\n",
       " 'govern': 326,\n",
       " 'employe': 327,\n",
       " 'live': 328,\n",
       " 'oversea': 329,\n",
       " 'countri': 330,\n",
       " 'assign': 331,\n",
       " 'alway': 332,\n",
       " 'tasti': 333,\n",
       " 'manner': 334,\n",
       " 'current': 335,\n",
       " 'appar': 336,\n",
       " 'staff': 337,\n",
       " 'generous': 338,\n",
       " 'worth': 339,\n",
       " 'href': 340,\n",
       " 'http': 341,\n",
       " 'www': 342,\n",
       " 'com': 343,\n",
       " 'gvisjm': 344,\n",
       " 'rememb': 345,\n",
       " 'drop': 346,\n",
       " 'still': 347,\n",
       " 'superb': 348,\n",
       " 'disappoint': 349,\n",
       " 'watcher': 350,\n",
       " 'crave': 351,\n",
       " 'yrs': 352,\n",
       " 'miss': 353,\n",
       " 'visit': 354,\n",
       " 'someon': 355,\n",
       " 'stock': 356,\n",
       " 'say': 357,\n",
       " 'yum': 358,\n",
       " 'mexico': 359,\n",
       " 'faith': 360,\n",
       " 'buyer': 361,\n",
       " 'often': 362,\n",
       " 'abl': 363,\n",
       " 'receiv': 364,\n",
       " 'advertis': 365,\n",
       " 'plan': 366,\n",
       " 'glad': 367,\n",
       " 'carri': 368,\n",
       " 'batteri': 369,\n",
       " 'hard': 370,\n",
       " 'elsewher': 371,\n",
       " 'garag': 372,\n",
       " 'door': 373,\n",
       " 'open': 374,\n",
       " 'mum': 375,\n",
       " 'diabet': 376,\n",
       " 'intak': 377,\n",
       " 'father': 378,\n",
       " 'choos': 379,\n",
       " 'limit': 380,\n",
       " 'unnecessari': 381,\n",
       " 'tooth': 382,\n",
       " 'toffe': 383,\n",
       " 'guess': 384,\n",
       " 'free': 385,\n",
       " 'pretti': 386,\n",
       " 'guilt': 387,\n",
       " 'impress': 388,\n",
       " 'dark': 389,\n",
       " 'chocol': 390,\n",
       " 'offic': 391,\n",
       " 'instead': 392,\n",
       " 'snack': 393,\n",
       " 'sugari': 394,\n",
       " 'excel': 395,\n",
       " 'huge': 396,\n",
       " 'coffe': 397,\n",
       " 'fan': 398,\n",
       " 'howev': 399,\n",
       " 'mother': 400,\n",
       " 'littl': 401,\n",
       " 'machin': 402,\n",
       " 'talk': 403,\n",
       " 'latt': 404,\n",
       " 'macciato': 405,\n",
       " 'shop': 406,\n",
       " 'usual': 407,\n",
       " 'non': 408,\n",
       " 'drinker': 409,\n",
       " 'dolch': 410,\n",
       " 'guesto': 411,\n",
       " 'super': 412,\n",
       " 'easi': 413,\n",
       " 'prepar': 414,\n",
       " 'cappuccino': 415,\n",
       " 'less': 416,\n",
       " 'minut': 417,\n",
       " 'water': 418,\n",
       " 'heat': 419,\n",
       " 'dolc': 420,\n",
       " 'gusto': 421,\n",
       " 'anyon': 422,\n",
       " 'offer': 423,\n",
       " 'staral': 424,\n",
       " 'mccann': 425,\n",
       " 'instant': 426,\n",
       " 'oatmeal': 427,\n",
       " 'must': 428,\n",
       " 'scrape': 429,\n",
       " 'three': 430,\n",
       " 'escap': 431,\n",
       " 'fact': 432,\n",
       " 'even': 433,\n",
       " 'best': 434,\n",
       " 'nowher': 435,\n",
       " 'near': 436,\n",
       " 'stovetop': 437,\n",
       " 'organ': 438,\n",
       " 'natur': 439,\n",
       " 'varieti': 440,\n",
       " 'microwav': 441,\n",
       " 'boil': 442,\n",
       " 'conveni': 443,\n",
       " 'extrem': 444,\n",
       " 'issu': 445,\n",
       " 'cane': 446,\n",
       " 'fructos': 447,\n",
       " 'corn': 448,\n",
       " 'syrup': 449,\n",
       " 'help': 450,\n",
       " 'decid': 451,\n",
       " 'real': 452,\n",
       " 'harm': 453,\n",
       " 'stuff': 454,\n",
       " 'thing': 455,\n",
       " 'though': 456,\n",
       " 'thicken': 457,\n",
       " 'oat': 458,\n",
       " 'plus': 459,\n",
       " 'creami': 460,\n",
       " 'without': 461,\n",
       " 'guar': 462,\n",
       " 'gum': 463,\n",
       " 'mayb': 464,\n",
       " 'becom': 465,\n",
       " 'thick': 466,\n",
       " 'gluey': 467,\n",
       " 'fructous': 468,\n",
       " 'doctor': 469,\n",
       " 'form': 470,\n",
       " 'cold': 471,\n",
       " 'morn': 472,\n",
       " 'steel': 473,\n",
       " 'cinnamon': 474,\n",
       " 'mapl': 475,\n",
       " 'brown': 476,\n",
       " 'regular': 477,\n",
       " 'tell': 478,\n",
       " 'apart': 479,\n",
       " 'soggi': 480,\n",
       " 'hold': 481,\n",
       " 'textur': 482,\n",
       " 'meal': 483,\n",
       " 'may': 484,\n",
       " 'longer': 485,\n",
       " 'eaten': 486,\n",
       " 'close': 487,\n",
       " 'second': 488,\n",
       " 'irish': 489,\n",
       " 'count': 490,\n",
       " 'box': 491,\n",
       " 'thought': 492,\n",
       " 'give': 493,\n",
       " 'hardi': 494,\n",
       " 'folk': 495,\n",
       " 'post': 496,\n",
       " 'bariatr': 497,\n",
       " 'surgeri': 498,\n",
       " 'palat': 499,\n",
       " 'easili': 500,\n",
       " 'fiber': 501,\n",
       " 'bloat': 502,\n",
       " 'celiac': 503,\n",
       " 'diseas': 504,\n",
       " 'lifesav': 505,\n",
       " 'could': 506,\n",
       " 'almost': 507,\n",
       " 'half': 508,\n",
       " 'groceri': 509,\n",
       " 'health': 510,\n",
       " 'abbi': 511,\n",
       " 'els': 512,\n",
       " 'cup': 513,\n",
       " 'low': 514,\n",
       " 'fat': 515,\n",
       " 'milk': 516,\n",
       " 'add': 517,\n",
       " 'raisin': 518,\n",
       " 'nuke': 519,\n",
       " 'kroger': 520,\n",
       " 'tastier': 521,\n",
       " 'someth': 522,\n",
       " 'mmm': 523,\n",
       " 'friend': 524,\n",
       " 'nate': 525,\n",
       " 'storag': 526,\n",
       " 'room': 527,\n",
       " 'packet': 528,\n",
       " 'suggest': 529,\n",
       " 'stash': 530,\n",
       " 'sometim': 531,\n",
       " 'dose': 532,\n",
       " 'chanc': 533,\n",
       " 'end': 534,\n",
       " 'cinn': 535,\n",
       " 'tasteful': 536,\n",
       " 'goe': 537,\n",
       " 'slice': 538,\n",
       " 'toast': 539,\n",
       " 'readi': 540,\n",
       " 'day': 541,\n",
       " 'least': 542,\n",
       " 'jerri': 543,\n",
       " 'reith': 544,\n",
       " 'wife': 545,\n",
       " 'reccomend': 546,\n",
       " 'happi': 547,\n",
       " 'cent': 548,\n",
       " 'per': 549,\n",
       " 'understand': 550,\n",
       " 'earth': 551,\n",
       " 'terrif': 552,\n",
       " 'follow': 553,\n",
       " 'tire': 554,\n",
       " 'ole': 555,\n",
       " 'pot': 556,\n",
       " 'empti': 557,\n",
       " 'pour': 558,\n",
       " 'expand': 559,\n",
       " 'cheap': 560,\n",
       " 'connoisseur': 561,\n",
       " 'whether': 562,\n",
       " 'raw': 563,\n",
       " 'pellet': 564,\n",
       " 'cook': 565,\n",
       " 'hour': 566,\n",
       " 'sloth': 567,\n",
       " 'addl': 568,\n",
       " 'done': 569,\n",
       " 'beauti': 570,\n",
       " 'avail': 571,\n",
       " 'allow': 572,\n",
       " 'explor': 573,\n",
       " 'experi': 574,\n",
       " 'known': 575,\n",
       " 'thicker': 576,\n",
       " 'bodi': 577,\n",
       " 'top': 578,\n",
       " 'america': 579,\n",
       " 'tend': 580,\n",
       " 'liquidi': 581,\n",
       " 'watt': 582,\n",
       " 'twenti': 583,\n",
       " 'seven': 584,\n",
       " 'handl': 585,\n",
       " 'bad': 586,\n",
       " 'consid': 587,\n",
       " 'lot': 588,\n",
       " 'ten': 589,\n",
       " 'whole': 590,\n",
       " 'famili': 591,\n",
       " 'eater': 592,\n",
       " 'singl': 593,\n",
       " 'alon': 594,\n",
       " 'save': 595,\n",
       " 'choic': 596,\n",
       " 'over': 597,\n",
       " 'breakfast': 598,\n",
       " 'anyth': 599,\n",
       " 'seem': 600,\n",
       " 'wholesom': 601,\n",
       " 'supermarket': 602,\n",
       " 'somewhat': 603,\n",
       " 'mushi': 604,\n",
       " 'quit': 605,\n",
       " 'either': 606,\n",
       " 'pass': 607,\n",
       " 'muster': 608,\n",
       " 'probabl': 609,\n",
       " 'direct': 610,\n",
       " 'sinc': 611,\n",
       " 'come': 612,\n",
       " 'soupi': 613,\n",
       " 'see': 614,\n",
       " 'differc': 615,\n",
       " 'oaker': 616,\n",
       " 'fine': 617,\n",
       " 'big': 618,\n",
       " 'noth': 619,\n",
       " 'carb': 620,\n",
       " 'money': 621,\n",
       " 'quaker': 622,\n",
       " 'way': 623,\n",
       " 'bloodi': 624,\n",
       " 'mari': 625,\n",
       " 'mix': 626,\n",
       " 'seller': 627,\n",
       " 'work': 628,\n",
       " 'lol': 629,\n",
       " 'buddi': 630,\n",
       " 'yet': 631,\n",
       " 'forev': 632,\n",
       " 'nice': 633,\n",
       " 'temp': 634,\n",
       " 'vermont': 635,\n",
       " 'weston': 636,\n",
       " 'along': 637,\n",
       " 'jaw': 638,\n",
       " 'harp': 639,\n",
       " 'cranberri': 640,\n",
       " 'horseradish': 641,\n",
       " 'fartless': 642,\n",
       " 'bean': 643,\n",
       " 'salsa': 644,\n",
       " 'cider': 645,\n",
       " 'jelli': 646,\n",
       " 'newton': 647,\n",
       " 'cradl': 648,\n",
       " 'art': 649,\n",
       " 'motion': 650,\n",
       " 'stapl': 651,\n",
       " 'ass': 652,\n",
       " 'kickin': 653,\n",
       " 'activ': 654,\n",
       " 'perspir': 655,\n",
       " 'gland': 656,\n",
       " 'behind': 657,\n",
       " 'ear': 658,\n",
       " 'arm': 659,\n",
       " 'beverag': 660,\n",
       " 'glass': 661,\n",
       " 'kleenex': 662,\n",
       " 'nose': 663,\n",
       " 'run': 664,\n",
       " 'ordinari': 665,\n",
       " 'alreadi': 666,\n",
       " 'idea': 667,\n",
       " 'suspect': 668,\n",
       " 'peopl': 669,\n",
       " 'goodi': 670,\n",
       " 'absenc': 671,\n",
       " 'especi': 672,\n",
       " 'colleagu': 673,\n",
       " 'greg': 674,\n",
       " 'earliest': 675,\n",
       " 'opportun': 676,\n",
       " 'content': 677,\n",
       " 'planter': 678,\n",
       " 'whose': 679,\n",
       " 'cri': 680,\n",
       " 'return': 681,\n",
       " 'shaken': 682,\n",
       " 'ensur': 683,\n",
       " 'spice': 684,\n",
       " 'distribut': 685,\n",
       " 'import': 686,\n",
       " 'wash': 687,\n",
       " 'hand': 688,\n",
       " 'consumpt': 689,\n",
       " 'eye': 690,\n",
       " 'deliber': 691,\n",
       " 'christma': 692,\n",
       " 'insult': 693,\n",
       " 'spici': 694,\n",
       " 'south': 695,\n",
       " 'texa': 696,\n",
       " 'doubt': 697,\n",
       " 'habanero': 698,\n",
       " 'notch': 699,\n",
       " 'roast': 700,\n",
       " 'stove': 701,\n",
       " 'popcorn': 702,\n",
       " 'popper': 703,\n",
       " 'outsid': 704,\n",
       " 'cours': 705,\n",
       " 'mexican': 706,\n",
       " 'altura': 707,\n",
       " 'suit': 708,\n",
       " 'method': 709,\n",
       " 'crack': 710,\n",
       " 'distinct': 711,\n",
       " 'medium': 712,\n",
       " 'slight': 713,\n",
       " 'result': 714,\n",
       " 'aroma': 715,\n",
       " 'strong': 716,\n",
       " 'persist': 717,\n",
       " 'smooth': 718,\n",
       " 'velveti': 719,\n",
       " 'larg': 720,\n",
       " 'cast': 721,\n",
       " 'iron': 722,\n",
       " 'pan': 723,\n",
       " 'grill': 724,\n",
       " 'wonder': 725,\n",
       " 'bitter': 726,\n",
       " 'aftertast': 727,\n",
       " 'numer': 728,\n",
       " 'occas': 729,\n",
       " 'send': 730,\n",
       " 'awesom': 731,\n",
       " 'halloween': 732,\n",
       " 'indic': 733,\n",
       " 'enough': 734,\n",
       " 'trick': 735,\n",
       " 'treater': 736,\n",
       " 'local': 737,\n",
       " 'everyth': 738,\n",
       " 'kit': 739,\n",
       " 'kat': 740,\n",
       " 'rees': 741,\n",
       " 'plenti': 742,\n",
       " 'ship': 743,\n",
       " 'prompt': 744,\n",
       " 'neighborhood': 745,\n",
       " 'sent': 746,\n",
       " 'class': 747,\n",
       " 'gold': 748,\n",
       " 'target': 749,\n",
       " 'onlin': 750,\n",
       " 'cheaper': 751,\n",
       " 'compet': 752,\n",
       " 'endurolyt': 753,\n",
       " 'pill': 754,\n",
       " 'long': 755,\n",
       " 'desert': 756,\n",
       " 'ride': 757,\n",
       " 'dirt': 758,\n",
       " 'bike': 759,\n",
       " 'camelbak': 760,\n",
       " 'heavili': 761,\n",
       " 'lace': 762,\n",
       " 'effect': 763,\n",
       " 'cramp': 764,\n",
       " 'hundr': 765,\n",
       " 'mile': 766,\n",
       " 'race': 767,\n",
       " 'buggi': 768,\n",
       " 'fizz': 769,\n",
       " 'hammer': 770,\n",
       " 'endur': 771,\n",
       " 'athlet': 772,\n",
       " 'tablet': 773,\n",
       " 'dissovl': 774,\n",
       " 'third': 775,\n",
       " 'imagin': 776,\n",
       " 'drink': 777,\n",
       " 'starv': 778,\n",
       " 'hydrat': 779,\n",
       " 'electrolyt': 780,\n",
       " 'rather': 781,\n",
       " 'salti': 782,\n",
       " 'refresh': 783,\n",
       " 'lemon': 784,\n",
       " 'lime': 785,\n",
       " 'mango': 786,\n",
       " 'whenev': 787,\n",
       " 'exercis': 788,\n",
       " 'chock': 789,\n",
       " 'cannot': 790,\n",
       " 'sourc': 791,\n",
       " 'grapefruit': 792,\n",
       " 'carbon': 793,\n",
       " 'line': 794,\n",
       " 'prevent': 795,\n",
       " 'middl': 796,\n",
       " 'latter': 797,\n",
       " 'stage': 798,\n",
       " 'pop': 799,\n",
       " 'set': 800,\n",
       " 'diet': 801,\n",
       " 'ago': 802,\n",
       " 'start': 803,\n",
       " 'cycl': 804,\n",
       " 'heart': 805,\n",
       " 'arrhythmia': 806,\n",
       " 'plain': 807,\n",
       " 'research': 808,\n",
       " 'might': 809,\n",
       " 'gatorad': 810,\n",
       " 'option': 811,\n",
       " 'load': 812,\n",
       " 'carbohydr': 813,\n",
       " 'altern': 814,\n",
       " 'zero': 815,\n",
       " 'sport': 816,\n",
       " 'ran': 817,\n",
       " 'across': 818,\n",
       " 'tube': 819,\n",
       " 'voila': 820,\n",
       " 'problem': 821,\n",
       " 'solv': 822,\n",
       " 'leg': 823,\n",
       " 'resolv': 824,\n",
       " 'superbl': 825,\n",
       " 'formul': 826,\n",
       " 'hint': 827,\n",
       " 'consum': 828,\n",
       " 'various': 829,\n",
       " 'nutrit': 830,\n",
       " 'decad': 831,\n",
       " 'appeal': 832,\n",
       " 'terribl': 833,\n",
       " 'sip': 834,\n",
       " 'impuls': 835,\n",
       " 'wrong': 836,\n",
       " 'babi': 837,\n",
       " 'retrospect': 838,\n",
       " 'ridicul': 839,\n",
       " 'esp': 840,\n",
       " 'sooooo': 841,\n",
       " 'delisci': 842,\n",
       " 'ate': 843,\n",
       " 'gain': 844,\n",
       " 'pds': 845,\n",
       " 'fault': 846,\n",
       " 'albanes': 847,\n",
       " 'gummi': 848,\n",
       " 'bear': 849,\n",
       " 'ring': 850,\n",
       " 'face': 851,\n",
       " 'type': 852,\n",
       " 'snake': 853,\n",
       " 'ball': 854,\n",
       " 'worm': 855,\n",
       " 'whatev': 856,\n",
       " 'twin': 857,\n",
       " 'scream': 858,\n",
       " 'far': 859,\n",
       " 'concern': 860,\n",
       " 'deep': 861,\n",
       " 'friggin': 862,\n",
       " 'area': 863,\n",
       " 'think': 864,\n",
       " 'lie': 865,\n",
       " 'lbs': 866,\n",
       " 'bigger': 867,\n",
       " 'sour': 868,\n",
       " 'kick': 869,\n",
       " 'anoth': 870,\n",
       " 'opinion': 871,\n",
       " 'popsicl': 872,\n",
       " 'softer': 873,\n",
       " 'frozen': 874,\n",
       " 'latic': 875,\n",
       " 'tart': 876,\n",
       " 'fantasicak': 877,\n",
       " 'websit': 878,\n",
       " 'dinner': 879,\n",
       " 'host': 880,\n",
       " 'intact': 881,\n",
       " 'froze': 882,\n",
       " 'later': 883,\n",
       " 'pastri': 884,\n",
       " 'jam': 885,\n",
       " 'gone': 886,\n",
       " 'guest': 887,\n",
       " 'bewar': 888,\n",
       " 'pleas': 889,\n",
       " 'sweeten': 890,\n",
       " 'everybodi': 891,\n",
       " 'maltitol': 892,\n",
       " 'alcohol': 893,\n",
       " 'undigest': 894,\n",
       " 'short': 895,\n",
       " 'unsuspect': 896,\n",
       " 'intestin': 897,\n",
       " 'massiv': 898,\n",
       " 'gas': 899,\n",
       " 'nausea': 900,\n",
       " 'diarrhea': 901,\n",
       " 'headach': 902,\n",
       " 'experienc': 903,\n",
       " 'learn': 904,\n",
       " 'lesson': 905,\n",
       " 'fell': 906,\n",
       " 'suzann': 907,\n",
       " 'sommer': 908,\n",
       " 'nirvana': 909,\n",
       " 'bliss': 910,\n",
       " 'side': 911,\n",
       " 'discomfort': 912,\n",
       " 'unlik': 913,\n",
       " 'felt': 914,\n",
       " 'blew': 915,\n",
       " 'balloon': 916,\n",
       " 'pain': 917,\n",
       " 'abdomin': 918,\n",
       " 'symptom': 919,\n",
       " 'unpleas': 920,\n",
       " 'calori': 921,\n",
       " 'culprit': 922,\n",
       " 'stop': 923,\n",
       " 'hunch': 924,\n",
       " 'confirm': 925,\n",
       " 'market': 926,\n",
       " 'possibl': 927,\n",
       " 'sugarfre': 928,\n",
       " 'sank': 929,\n",
       " 'asterisk': 930,\n",
       " 'next': 931,\n",
       " 'bottom': 932,\n",
       " 'read': 933,\n",
       " 'letter': 934,\n",
       " 'shorter': 935,\n",
       " 'durat': 936,\n",
       " 'reaction': 937,\n",
       " 'okay': 938,\n",
       " 'tea': 939,\n",
       " 'brunch': 940,\n",
       " 'artifi': 941,\n",
       " 'wast': 942,\n",
       " 'buck': 943,\n",
       " 'trail': 944,\n",
       " 'solid': 945,\n",
       " 'mass': 946,\n",
       " 'melt': 947,\n",
       " 'left': 948,\n",
       " 'pantri': 949,\n",
       " 'temperatur': 950,\n",
       " 'gooey': 951,\n",
       " 'hunk': 952,\n",
       " 'graini': 953,\n",
       " 'solidifi': 954,\n",
       " 'agre': 955,\n",
       " 'regard': 956,\n",
       " 'summer': 957,\n",
       " 'insul': 958,\n",
       " 'ice': 959,\n",
       " 'warm': 960,\n",
       " 'weather': 961,\n",
       " 'item': 962,\n",
       " 'berri': 963,\n",
       " 'winter': 964,\n",
       " 'grant': 965,\n",
       " 'crisp': 966,\n",
       " 'stick': 967,\n",
       " 'fun': 968,\n",
       " 'dad': 969,\n",
       " 'girl': 970,\n",
       " 'gift': 971,\n",
       " 'age': 972,\n",
       " 'giant': 973,\n",
       " 'recipi': 974,\n",
       " 'kept': 975,\n",
       " 'titl': 976,\n",
       " 'molecular': 977,\n",
       " 'gastronomi': 978,\n",
       " 'let': 979,\n",
       " 'scare': 980,\n",
       " 'scienc': 981,\n",
       " 'creamer': 982,\n",
       " 'blond': 983,\n",
       " 'honest': 984,\n",
       " 'hate': 985,\n",
       " 'manufactur': 986,\n",
       " 'cream': 987,\n",
       " 'stumbl': 988,\n",
       " 'lowfat': 989,\n",
       " 'sweeter': 990,\n",
       " 'fresher': 991,\n",
       " 'dissolv': 992,\n",
       " 'play': 993,\n",
       " 'ratio': 994,\n",
       " 'heavi': 995,\n",
       " 'bough': 996,\n",
       " 'cocoa': 997,\n",
       " 'vanilla': 998,\n",
       " 'caster': 999,\n",
       " 'superfin': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vocanulary of each word\n",
    "vocabulary={}\n",
    "index=1\n",
    "\n",
    "for text in tqdm(df_snow['Text_snow']):\n",
    "    for word in text:\n",
    "        if word not in vocabulary and len(word)>2:\n",
    "            vocabulary[word]=index\n",
    "            index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78973"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save vocabulary as pickle file\n",
    "with open('/Users/domenicospoto/Desktop/Sapienza/MScDataScience/AlgorithmicMethodsofDataMiningandLaboratory/HW4/vocabulary.pkl', 'wb') as handle:\n",
    "    pickle.dump(vocabulary, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open vocabulary to pickle\n",
    "with open('/Users/domenicospoto/Desktop/Sapienza/MScDataScience/AlgorithmicMethodsofDataMiningandLaboratory/HW4/vocabulary.pkl', 'rb') as handle:\n",
    "    vocabulary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 568454/568454 [00:16<00:00, 33814.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# create an length documents dict\n",
    "\n",
    "length_doc = {}\n",
    "\n",
    "for text in tqdm(df_snow['Text_snow']):\n",
    "    p = list(set(text))\n",
    "    for word in p:\n",
    "        if len(word)<=2:\n",
    "            continue\n",
    "        if vocabulary[word] in length_doc:\n",
    "            length_doc[vocabulary[word]]+=1\n",
    "        else:\n",
    "            length_doc[vocabulary[word]]=1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save length_doc as pickle file\n",
    "with open('/Users/domenicospoto/Desktop/Sapienza/MScDataScience/AlgorithmicMethodsofDataMiningandLaboratory/HW4/length_doc.pkl', 'wb') as handle:\n",
    "    pickle.dump(length_doc, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open length_doc to pickle\n",
    "with open('/Users/domenicospoto/Desktop/Sapienza/MScDataScience/AlgorithmicMethodsofDataMiningandLaboratory/HW4/length_doc.pkl', 'rb') as handle:\n",
    "    length_doc = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 568454/568454 [00:46<00:00, 12097.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# create an inverted index with tfidf scoring\n",
    "N_doc = len(df_snow)\n",
    "tfidf = defaultdict(list)\n",
    "\n",
    "count = 0\n",
    "for text in tqdm(df_snow['Text_snow']):\n",
    "    n_ij=dict(Counter(text))\n",
    "    for word in n_ij:\n",
    "        if len(word)<=2:\n",
    "            continue\n",
    "        \n",
    "        tf=n_ij[word]/len(text)\n",
    "        if tf <= 0.1 or tf >= 0.9:\n",
    "            continue\n",
    "        Idf=np.log(N_doc/length_doc[vocabulary[word]])\n",
    "        tfidf[vocabulary[word]].append((count,tf*Idf))\n",
    "        \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tfidf as pickle file\n",
    "with open('/Users/domenicospoto/Desktop/Sapienza/MScDataScience/AlgorithmicMethodsofDataMiningandLaboratory/HW4/tfidf.pkl', 'wb') as handle:\n",
    "    pickle.dump(tfidf, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open vocabulary to pickle\n",
    "with open('/Users/domenicospoto/Desktop/Sapienza/MScDataScience/AlgorithmicMethodsofDataMiningandLaboratory/HW4/tfidf.pkl', 'rb') as handle:\n",
    "    tfidf = pickle.load(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('algotrading': conda)",
   "language": "python",
   "name": "python37464bitalgotradingconda745421058edb4475bcdf684bffb17224"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
